# -*- coding: utf-8 -*-
"""LearningPyTorch.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19K7T1nsUh-VFUrWCayO_IuL7GE6vYSv3

#Polynomial Fitting with PyTorch
"""

import math

import numpy as np
import matplotlib.pyplot as plt

import torch
from torch import nn
from torch.utils.data import DataLoader
from torchvision import datasets
from torchvision.transforms import ToTensor

"""##Configuration"""

num_points = 1000
learning_rate = 1e-4
num_epochs = 2000
batch_size = 16

"""##Numpy, Hardcoded Derivatives and Update Equations"""

# create the dataset
num_points = 1000
X = np.linspace(-math.pi, math.pi, num_points)
y = np.sin(X)

# randomly initialize the weights
a = np.random.randn()
b = np.random.randn()
c = np.random.randn()

for epoch in range(num_epochs):
  y_pred = a + b*X + c*X**2 # predict
  loss = np.square(y_pred - y).sum()/num_points # compute the loss

  if epoch%100 == 99:
    print(f"Epoch {epoch} --> Loss {loss}")

  # compute the gradients
  grad_y_pred = 2.0*(y_pred - y)
  grad_a = grad_y_pred.sum()/num_points
  grad_b = (grad_y_pred * X).sum()/num_points
  grad_c = (grad_y_pred * X**2).sum()/num_points

  # backpropagate
  a -= learning_rate * grad_a
  b -= learning_rate * grad_b
  c -= learning_rate * grad_c

print(f"Polynomial is {a} + {b}x + {c}x^2")
plt.plot(X, y, label='Ground Truth')
plt.plot(X, a+b*X+c*X**2, label='Predicted')
plt.legend()
plt.show()

"""##PyTorch Tensor, Hardcoded Derivatives and Update Equations"""

dtype = torch.float
device = torch.device('cpu')

# create the dataset
num_points = 1000
X = torch.linspace(-math.pi, math.pi, num_points, device=device, dtype=dtype)
y = torch.sin(X)

# randomly initialize the weights
a = torch.randn((), device=device, dtype=dtype)
b = torch.randn((), device=device, dtype=dtype)
c = torch.randn((), device=device, dtype=dtype)

for epoch in range(num_epochs):
  y_pred = a + b*X + c*X**2 # predict
  loss = ((y_pred - y).pow(2).sum()/num_points).item() # compute the loss

  if epoch%100 == 99:
    print(f"Epoch {epoch} --> Loss {loss}")

  # compute the gradients
  grad_y_pred = 2.0*(y_pred - y)
  grad_a = grad_y_pred.sum()/num_points
  grad_b = (grad_y_pred * X).sum()/num_points
  grad_c = (grad_y_pred * X**2).sum()/num_points

  # backpropagate
  a -= learning_rate * grad_a
  b -= learning_rate * grad_b
  c -= learning_rate * grad_c

print(f"Polynomial is {a.item()} + {b.item()}x + {c.item()}x^2")
plt.plot(X, y, label='Ground Truth')
plt.plot(X, (a+b*X+c*X**2), label='Predicted')
plt.legend()
plt.show()

"""##PyTorch, Autograd, Harcoded Update Equations"""

dtype = torch.float
device = torch.device('cpu')

# create the dataset
X = torch.linspace(-math.pi, math.pi, num_points, device=device, dtype=dtype)
y = torch.sin(X)

# randomly initialize the weights
a = torch.randn((), device=device, dtype=dtype, requires_grad=True)
b = torch.randn((), device=device, dtype=dtype, requires_grad=True)
c = torch.randn((), device=device, dtype=dtype, requires_grad=True)

for epoch in range(num_epochs):
  y_pred = a + b*X + c*X**2 # predict
  loss = ((y_pred - y).pow(2).sum()/num_points) # compute the loss

  if epoch%100 == 99:
    print(f"Epoch {epoch} --> Loss {loss.item()}")

  # compute the gradients
  loss.backward()

  # backpropagate, don't track in autograd
  with torch.no_grad():
    a -= learning_rate * a.grad
    b -= learning_rate * b.grad
    c -= learning_rate * c.grad

    # reset the gradients to zero
    a.grad = None
    b.grad = None
    c.grad = None

print(f"Polynomial is {a.item()} + {b.item()}x + {c.item()}x^2")
plt.plot(X, y, label='Ground Truth')
plt.plot(X, (a+b*X+c*X**2).detach().numpy(), label='Predicted')
plt.legend()
plt.show()

"""##PyTorch, Autograd, Torch Optim SGD Library"""

dtype = torch.float
device = torch.device('cpu')

# create the dataset
X = torch.linspace(-math.pi, math.pi, num_points, device=device, dtype=dtype)
y = torch.sin(X)

# randomly initialize the weights
a = torch.randn((), device=device, dtype=dtype, requires_grad=True)
b = torch.randn((), device=device, dtype=dtype, requires_grad=True)
c = torch.randn((), device=device, dtype=dtype, requires_grad=True)

optimizer = torch.optim.SGD([a,b,c], lr=learning_rate, momentum=0)

for epoch in range(num_epochs):
  y_pred = a + b*X + c*X**2 # predict
  loss = ((y_pred - y).pow(2).sum()/num_points) # compute the loss

  if epoch%100 == 99:
    print(f"Epoch {epoch} --> Loss {loss.item()}")

  # set the gradients to zero
  optimizer.zero_grad()

  # compute the gradients
  loss.backward()

  # backpropagate
  optimizer.step()

print(f"Polynomial is {a.item()} + {b.item()}x + {c.item()}x^2")
plt.plot(X, y, label='Ground Truth')
plt.plot(X, (a+b*X+c*X**2).detach().numpy(), label='Predicted')
plt.legend()
plt.show()

"""## Custom Mean Squared Error Loss Function"""

# MSE Loss
def mse(predicted, ground_truth):
  return (predicted - ground_truth).pow(2).sum()/len(predicted)

dtype = torch.float
device = torch.device('cpu')

# create the dataset
X = torch.linspace(-math.pi, math.pi, num_points, device=device, dtype=dtype)
y = torch.sin(X)

# randomly initialize the weights
a = torch.randn((), device=device, dtype=dtype, requires_grad=True)
b = torch.randn((), device=device, dtype=dtype, requires_grad=True)
c = torch.randn((), device=device, dtype=dtype, requires_grad=True)

optimizer = torch.optim.SGD([a,b,c], lr=learning_rate, momentum=0)

for epoch in range(num_epochs):
  y_pred = a + b*X + c*X**2 # predict
  loss = mse(y_pred, y) # compute the loss

  if epoch%100 == 99:
    print(f"Epoch {epoch} --> Loss {loss.item()}")

  # set the gradients to zero
  optimizer.zero_grad()

  # compute the gradients
  loss.backward()

  # backpropagate
  optimizer.step()

print(f"Polynomial is {a.item()} + {b.item()}x + {c.item()}x^2")
plt.plot(X, y, label='Ground Truth')
plt.plot(X, (a+b*X+c*X**2).detach().numpy(), label='Predicted')
plt.legend()
plt.show()

"""##Data Loading with DataLoader and Dataset Subclasses and a batch size of 16

###Dataset Subclass
"""

class MyDataset(torch.utils.data.Dataset):
  def __init__(self, X, y):
    self.X = X
    self.y = y

  def __len__(self):
    return len(self.X)

  def __getitem__(self, idx):
    return self.X[idx], self.y[idx]

"""###Create and load the dataset"""

X = torch.linspace(-math.pi, math.pi, num_points, device=device, dtype=dtype)
y = torch.sin(X)

my_dataloader = torch.utils.data.DataLoader(MyDataset(X, y), batch_size=batch_size, shuffle=True)

# MSE Loss
def mse(predicted, ground_truth):
  return (predicted - ground_truth).pow(2).sum()/len(predicted)

dtype = torch.float
device = torch.device('cpu')

# randomly initialize the weights
a = torch.randn((), device=device, dtype=dtype, requires_grad=True)
b = torch.randn((), device=device, dtype=dtype, requires_grad=True)
c = torch.randn((), device=device, dtype=dtype, requires_grad=True)

optimizer = torch.optim.SGD([a,b,c], lr=learning_rate, momentum=0)

for epoch in range(num_epochs):
  for data in my_dataloader:
    X_batch, y_batch = data
    y_batch_pred = a + b*X_batch + c*X_batch**2 # predict
    loss = mse(y_batch_pred, y_batch) # compute the loss

    # set the gradients to zero
    optimizer.zero_grad()

    # compute the gradients
    loss.backward()

    # backpropagate
    optimizer.step()

  if epoch%100 == 99:
      print(f"Epoch {epoch} --> Loss {loss.item()}")

print(f"Polynomial is {a.item()} + {b.item()}x + {c.item()}x^2")
plt.plot(X, y, label='Ground Truth')
plt.plot(X, (a+b*X+c*X**2).detach().numpy(), label='Predicted')
plt.legend()
plt.show()