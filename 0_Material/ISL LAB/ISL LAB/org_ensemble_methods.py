# -*- coding: utf-8 -*-
"""Ensemble Methods.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nYELy697smV7kP7seXOpqw5kVmbxVEWR
"""

# Author: Kalidas Y <ykalidas at iittp dot ac dot in>
# License: BSD 3 clause

from sklearn.ensemble import BaggingClassifier, BaggingRegressor
from sklearn.ensemble import AdaBoostClassifier, AdaBoostRegressor
from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor, RandomForestClassifier, RandomForestRegressor
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor
from sklearn.linear_model import LogisticRegression, LinearRegression

from sklearn.datasets import load_digits #,load_boston
from sklearn.model_selection import train_test_split

import numpy as np

from sklearn.base import BaseEstimator

"""# Data"""

Xc, yc = load_digits(return_X_y=True)

Xc_train, Xc_test, yc_train, yc_test = train_test_split(Xc,yc,test_size=0.3)

clf = DecisionTreeClassifier()
clf.fit(Xc,yc)

print (Xc.shape)
x0 = Xc[0]
print (x0.shape)

x0 = x0.reshape(1,-1)
print (x0.shape)

y0_pred_proba = clf.predict_proba(x0)

print (y0_pred_proba.shape)
print (y0_pred_proba)

clf.predict(x0)

"""# Bagging

## Bagging - Classification

### Bagging of Weak Classifiers - does Not Reduce Bias
"""

## REF - https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html

# Author: Kalidas Y <ykalidas at iittp dot ac dot in>
# License: BSD 3 clause

clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),n_estimators=100)
clf.fit(Xc_train,yc_train)
print (clf.score(Xc_test,yc_test))

"""### Bagging of Strong Classifiers - Reduces Bias and Reduces Variance"""

# Author: Kalidas Y <ykalidas at iittp dot ac dot in>
# License: BSD 3 clause

clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=10),n_estimators=100)

clf.fit(Xc_train,yc_train)

print (clf.score(Xc_test,yc_test))

"""### Bagging can also work with LogisticRegression or any other classifier as well"""

# Author: Kalidas Y <ykalidas at iittp dot ac dot in>
# License: BSD 3 clause

clf = BaggingClassifier(base_estimator=LogisticRegression(),n_estimators=100)

clf.fit(Xc_train,yc_train)

print (clf.score(Xc_test,yc_test))

"""## Bagging for Regression"""

from sklearn.datasets import load_boston
Xr, yr = load_boston(return_X_y=True)

Xr_train, Xr_test, yr_train, yr_test = train_test_split(Xr,yr,test_size=0.3)

# Author: Kalidas Y <ykalidas at iittp dot ac dot in>
# License: BSD 3 clause

reg = BaggingRegressor(base_estimator=LinearRegression(),n_estimators=100)
reg.fit(Xr_train,yr_train)
print (reg.score(Xr_test,yr_test))

# Author: Kalidas Y <ykalidas at iittp dot ac dot in>
# License: BSD 3 clause

reg = BaggingRegressor(base_estimator=DecisionTreeRegressor(max_depth=1),n_estimators=100)
reg.fit(Xr_train,yr_train)
print (reg.score(Xr_test,yr_test))

# Author: Kalidas Y <ykalidas at iittp dot ac dot in>
# License: BSD 3 clause

reg = BaggingRegressor(base_estimator=DecisionTreeRegressor(max_depth=10),n_estimators=100)
reg.fit(Xr_train,yr_train)
print (reg.score(Xr_test,yr_test))

"""# AdaBoost

## AdaBoost Classifier
"""

# Author: Kalidas Y <ykalidas at iittp dot ac dot in>
# License: BSD 3 clause

for n_est in [1, 10, 20, 50, 70, 100, 200, 300] :
    clf = AdaBoostClassifier(base_estimator=LogisticRegression(),n_estimators=n_est)
    clf.fit(Xc_train,yc_train)
    print ('Ada LogisticReg',n_est, round(clf.score(Xc_train,yc_train),2), round(clf.score(Xc_test,yc_test),2))

# Author: Kalidas Y <ykalidas at iittp dot ac dot in>
# License: BSD 3 clause

for n_est in [1, 10, 20, 50, 70, 100, 200, 300] :
    clf = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),n_estimators=n_est)
    clf.fit(Xc_train,yc_train)
    print ('Ada DT=1',n_est, round(clf.score(Xc_train,yc_train),2), round(clf.score(Xc_test,yc_test),2))

# Author: Kalidas Y <ykalidas at iittp dot ac dot in>
# License: BSD 3 clause

for n_est in [1, 10, 20, 50, 70, 100, 200, 300] :
    clf = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=2),n_estimators=n_est)
    clf.fit(Xc_train,yc_train)
    print ('Ada DT=2',n_est, round(clf.score(Xc_train,yc_train),2), round(clf.score(Xc_test,yc_test),2))

# Author: Kalidas Y <ykalidas at iittp dot ac dot in>
# License: BSD 3 clause

for n_est in [1, 10, 20, 50, 70, 100, 200, 300] :
    clf = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=3),n_estimators=n_est)
    clf.fit(Xc_train,yc_train)
    print ('Ada DT=3',n_est, round(clf.score(Xc_train,yc_train),2), round(clf.score(Xc_test,yc_test),2))

"""## AdaBoost Regressor"""

# Author: Kalidas Y <ykalidas at iittp dot ac dot in>
# License: BSD 3 clause

for n_est in [1, 10, 20, 50, 70, 100, 200, 300] :
    clf = AdaBoostRegressor(base_estimator=LinearRegression(),n_estimators=n_est)
    clf.fit(Xr_train,yr_train)
    print ('Ada LinReg',n_est, round(clf.score(Xr_train,yr_train),2), round(clf.score(Xr_test,yr_test),2))

# Author: Kalidas Y <ykalidas at iittp dot ac dot in>
# License: BSD 3 clause

for n_est in [1, 10, 20, 50, 70, 100, 200, 300] :
    clf = AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=1),n_estimators=n_est)
    clf.fit(Xr_train,yr_train)
    print ('Ada DT=1',n_est, round(clf.score(Xr_train,yr_train),2), round(clf.score(Xr_test,yr_test),2))

# Author: Kalidas Y <ykalidas at iittp dot ac dot in>
# License: BSD 3 clause

for n_est in [1, 10, 20, 50, 70, 100, 200, 300] :
    clf = AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=2),n_estimators=n_est)
    clf.fit(Xr_train,yr_train)
    print ('Ada DT=2',n_est, round(clf.score(Xr_train,yr_train),2), round(clf.score(Xr_test,yr_test),2))

# Author: Kalidas Y <ykalidas at iittp dot ac dot in>
# License: BSD 3 clause

for n_est in [1, 10, 20, 50, 70, 100, 200, 300] :
    clf = AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=3),n_estimators=n_est)
    clf.fit(Xr_train,yr_train)
    print ('Ada DT=3',n_est, round(clf.score(Xr_train,yr_train),2), round(clf.score(Xr_test,yr_test),2))

"""# Gradient Boosting"""

# Author: Kalidas Y <ykalidas at iittp dot ac dot in>
# License: BSD 3 clause

for n_est in [1, 10, 20, 50, 70, 100, 200, 300] :
    clf = GradientBoostingClassifier(n_estimators=n_est)
    clf.fit(Xc_train,yc_train)
    print ('GBC',n_est, round(clf.score(Xc_train,yc_train),2), round(clf.score(Xc_test,yc_test),2))

# Author: Kalidas Y <ykalidas at iittp dot ac dot in>
# License: BSD 3 clause

for n_est in [1, 10, 20, 50, 70, 100, 200, 300] :
    clf = GradientBoostingRegressor(n_estimators=n_est)
    clf.fit(Xr_train,yr_train)
    print ('GBR',n_est, round(clf.score(Xr_train,yr_train),2), round(clf.score(Xr_test,yr_test),2))

"""# Random Forest

## Random Forest Classifier
"""

clf = RandomForestClassifier()

clf.fit(Xc_train,yc_train)

print (clf.score(Xc_test,yc_test))

for n_est in [1, 10, 20, 50, 70, 100, 200, 300] :
    clf = RandomForestClassifier(n_estimators=n_est)
    clf.fit(Xc_train,yc_train)
    print ('RF',n_est, round(clf.score(Xc_train,yc_train),2), round(clf.score(Xc_test,yc_test),2))

for n_est in [1, 10, 20, 50, 70, 100, 200, 300] :
    clf = RandomForestClassifier(n_estimators=n_est,max_depth=1)
    clf.fit(Xc_train,yc_train)
    print ('RF Depth=1',n_est, round(clf.score(Xc_train,yc_train),2), round(clf.score(Xc_test,yc_test),2))

for n_est in [1, 10, 20, 50, 70, 100, 200, 300] :
    clf = RandomForestClassifier(n_estimators=n_est,max_depth=4)
    clf.fit(Xc_train,yc_train)
    print ('RF Depth=4',n_est, round(clf.score(Xc_train,yc_train),2), round(clf.score(Xc_test,yc_test),2))

for n_est in [1, 10, 20, 50, 70, 100, 200, 300] :
    clf = RandomForestClassifier(n_estimators=n_est,max_depth=None)
    clf.fit(Xc_train,yc_train)
    print ('RF Depth=None',n_est, round(clf.score(Xc_train,yc_train),2), round(clf.score(Xc_test,yc_test),2))

"""## Random Forest Regressor"""

clf = RandomForestRegressor()

clf.fit(Xr_train,yr_train)

print (clf.score(Xr_test,yr_test))

for n_est in [1, 10, 20, 50, 70, 100, 200, 300] :
    clf = RandomForestRegressor(n_estimators=n_est)
    clf.fit(Xr_train,yr_train)
    print ('RF',n_est, round(clf.score(Xr_train,yr_train),2), round(clf.score(Xr_test,yr_test),2))

for n_est in [1, 10, 20, 50, 70, 100, 200, 300] :
    clf = RandomForestRegressor(n_estimators=n_est,max_depth=1)
    clf.fit(Xr_train,yr_train)
    print ('RF Depth=1',n_est, round(clf.score(Xr_train,yr_train),2), round(clf.score(Xr_test,yr_test),2))

for n_est in [1, 10, 20, 50, 70, 100, 200, 300] :
    clf = RandomForestRegressor(n_estimators=n_est,max_depth=4)
    clf.fit(Xr_train,yr_train)
    print ('RF Depth=4',n_est, round(clf.score(Xr_train,yr_train),2), round(clf.score(Xr_test,yr_test),2))

