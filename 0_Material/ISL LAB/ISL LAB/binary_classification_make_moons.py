# -*- coding: utf-8 -*-
"""binary_classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jl6b1O54IyW8053Di-pt0gS62FB-gs0s
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_moons, make_blobs, make_circles

# Generate 'make_moons' dataset
moons_data, moons_labels = make_moons(n_samples=100, noise=0.1, random_state=42)

# Generate 'make_blobs' dataset
blobs_data, blobs_labels = make_blobs(n_samples=100, centers=2, cluster_std=1.0, random_state=42)

# Generate 'make_circles' dataset
circles_data, circles_labels = make_circles(n_samples=100, noise=0.1, random_state=42)

# Plot the datasets
plt.figure(figsize=(15, 4))

# Plot 'make_moons' dataset
plt.subplot(1, 3, 1)
plt.scatter(moons_data[:, 0], moons_data[:, 1], c=moons_labels, cmap='viridis')
plt.title('make_moons dataset')

# Plot 'make_blobs' dataset
plt.subplot(1, 3, 2)
plt.scatter(blobs_data[:, 0], blobs_data[:, 1], c=blobs_labels, cmap='viridis')
plt.title('make_blobs dataset')

# Plot 'make_circles' dataset
plt.subplot(1, 3, 3)
plt.scatter(circles_data[:, 0], circles_data[:, 1], c=circles_labels, cmap='viridis')
plt.title('make_circles dataset')

plt.show()

from sklearn.datasets import make_moons
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_recall_fscore_support as fun_prfs

X,y = make_moons()

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.4)

clf =   LogisticRegression(solver='lbfgs')

clf.fit(X_train,y_train)

y_pred = clf.predict(X_test)

print (confusion_matrix(y_true=y_test,y_pred=y_pred).ravel())


print (fun_prfs(y_true=y_test,y_pred=y_pred))


import numpy as np
import matplotlib.pyplot as plt

from sklearn.metrics import confusion_matrix
from sklearn.utils.multiclass import unique_labels

class_names = ['0','1']

def plot_confusion_matrix(y_true, y_pred, classes,
                          normalize=False,
                          title=None,
                          cmap=plt.cm.Blues):

    if not title:
        if normalize:
            title = 'Normalized confusion matrix'
        else:
            title = 'Confusion matrix, without normalization'

    cm = confusion_matrix(y_true, y_pred)
    classes = [classes[i] for i in unique_labels(y_true, y_pred)]
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)

    fig, ax = plt.subplots()
    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)
    ax.figure.colorbar(im, ax=ax)
    ax.set(xticks=np.arange(cm.shape[1]),
           yticks=np.arange(cm.shape[0]),
           xticklabels=classes, yticklabels=classes,
           title=title,
           ylabel='True label',
           xlabel='Predicted label')

    plt.setp(ax.get_xticklabels(), rotation=45, ha="right",
             rotation_mode="anchor")

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            ax.text(j, i, format(cm[i, j], fmt),
                    ha="center", va="center",
                    color="white" if cm[i, j] > thresh else "black")
    fig.tight_layout()
    return ax


np.set_printoptions(precision=2)

y_pred = clf.predict(X_test)

plot_confusion_matrix(y_test, y_pred, classes=class_names, title='Confusion matrix')

# plt.show()

"""# PR Curve"""

from sklearn.metrics import precision_recall_curve

y_score = clf.predict_proba(X_test)[:,1]

precision, recall, thresholds = precision_recall_curve(y_test, y_score)


plt.plot(recall,precision,'*')
plt.plot(recall,precision)

plt.xlabel('Recall')
plt.ylabel('Precision')
plt.ylim([0.0, 1.05])
plt.xlim([0.0, 1.05])
plt.title('PR Curve for the moons data')


plt.figure()

thr1 = np.append(thresholds,[1.0])

plt.plot(thr1,precision,color='red',label='Precision')
plt.plot(thr1,recall,color='blue',label='Recall')
plt.xlabel('Threshold')
plt.ylabel('P or R')
plt.title('Threshold vs Metric')
plt.legend(loc='best')
plt.show()


from sklearn.metrics import roc_curve, auc

fpr, tpr, thresholds = roc_curve(y_true=y_test,y_score=y_score)

auc_score = auc(fpr,tpr)

plt.title('ROC Curve for the moons data' + '(AUC=' + str(auc_score) + ')')
plt.plot(fpr, tpr,'*')
plt.plot(fpr, tpr)

plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')

plt.xlim([0.0,1.05])
plt.ylim([0.0,1.05])
plt.show()

"""# Standard Metrics - Precision, Recall, F1, AUC"""

from sklearn.metrics import precision_recall_fscore_support, roc_auc_score

p,r,f,s = precision_recall_fscore_support(y_test,y_pred)

print (p,r,f,s)

print ('prfs',p[1],r[1],f[1],s[1])

y_pred_proba = clf.predict_proba(X_test)

auc = roc_auc_score(y_test,y_pred_proba[:,1])

print ('auc',auc)

import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_moons
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Generate 'make_moons' dataset
X, y = make_moons(n_samples=100, noise=0.1, random_state=42)

# Split the data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Create and train the logistic regression model
logistic_model = LogisticRegression()
logistic_model.fit(X_train_scaled, y_train)

# Make predictions on the test set
y_pred = logistic_model.predict(X_test_scaled)

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy:.2f}')

# Classification report
print("Classification Report:")
print(classification_report(y_test, y_pred))

# Confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)
print('Confusion Matrix:')
print(conf_matrix)