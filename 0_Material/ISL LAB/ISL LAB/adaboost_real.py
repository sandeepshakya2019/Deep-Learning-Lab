# -*- coding: utf-8 -*-
"""adaboost_real.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FaIKCgOJ_kdnAQe5sF2oBCZPV8WATbOf
"""

from sklearn.datasets import fetch_olivetti_faces
from sklearn.model_selection import train_test_split
from sklearn.ensemble import AdaBoostClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
import numpy as np

def calculate_mean_average_precision(y_true, y_pred):

    unique_classes = np.unique(y_true)
    avg_precisions = []

    for cls in unique_classes:
        # Get binary labels for the current class
        binary_true = np.where(y_true == cls, 1, 0)
        binary_pred = np.where(y_pred == cls, 1, 0)

        # Calculate precision for the current class
        precision = precision_score(binary_true, binary_pred, zero_division=1)

        # Append precision to list of average precisions
        avg_precisions.append(precision)

    mean_avg_precision = np.mean(avg_precisions)
    return mean_avg_precision

def evaluate_classifier(clf, X_train, y_train, X_test, y_test):
    clf.fit(X_train, y_train)
    y_train_pred = clf.predict(X_train)
    y_test_pred = clf.predict(X_test)

    train_accuracy = accuracy_score(y_train, y_train_pred)
    test_accuracy = accuracy_score(y_test, y_test_pred)
    precision = precision_score(y_test, y_test_pred, average='macro', zero_division=1)
    recall = recall_score(y_test, y_test_pred, average='macro', zero_division=1)
    classification_matrix = classification_report(y_test, y_test_pred, zero_division=1)
    mean_avg_precision = calculate_mean_average_precision(y_test, y_test_pred)

    print(f"Train Accuracy: {train_accuracy:.4f} | Test Accuracy: {test_accuracy:.4f}")
    print(f"Precision: {precision:.4f} | Recall: {recall:.4f}")
    print("Classification Report:\n", classification_matrix)
    print("Mean Average Precision:", mean_avg_precision)

faces_data = fetch_olivetti_faces()
X = faces_data.data
y = faces_data.target

# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# AdaBoost Classifier with Logistic Regression as base estimator
print("AdaBoost Classifier with Logistic Regression as base estimator:")
estimators_list = [1, 3,5]
for n_estimators in estimators_list:
    clf = AdaBoostClassifier(estimator=LogisticRegression(max_iter=1000), n_estimators=n_estimators, random_state=42)
    print(f"Number of estimators: {n_estimators}")
    evaluate_classifier(clf, X_train, y_train, X_test, y_test)
    print()

# AdaBoost Classifier with Decision Tree (max_depth=1) as base estimator
print("AdaBoost Classifier with Decision Tree (max_depth=1) as base estimator:")
for n_estimators in estimators_list:
    clf = AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=1), n_estimators=n_estimators, random_state=42)
    print(f"Number of estimators: {n_estimators}")
    evaluate_classifier(clf, X_train, y_train, X_test, y_test)
    print()

# AdaBoost Classifier with Decision Tree (max_depth=2) as base estimator
print("AdaBoost Classifier with Decision Tree (max_depth=2) as base estimator:")
for n_estimators in estimators_list:
    clf = AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=2), n_estimators=n_estimators, random_state=42)
    print(f"Number of estimators: {n_estimators}")
    evaluate_classifier(clf, X_train, y_train, X_test, y_test)
    print()