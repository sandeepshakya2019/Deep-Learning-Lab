{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uolLcgBephhj"
      },
      "source": [
        "## Lab 2_3 Double layer NN without nn.Linear (fully connected module) for MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lHvNf4k0phhl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(\"./\", train=True, transform=transforms.ToTensor(), download=True)\n",
        "testset = torchvision.datasets.MNIST(\"./\", train=False, transform=transforms.ToTensor(), download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TFeNTIkZphhl"
      },
      "outputs": [],
      "source": [
        "n_classes = len(trainset.classes)\n",
        "x_train = torch.flatten(trainset.data, start_dim=1)\n",
        "y_train = trainset.targets\n",
        "x_test = torch.flatten(testset.data, start_dim=1)\n",
        "y_test = testset.targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-D01nWE1qVaT"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(x_train)\n",
        "X_train = torch.tensor(scaler.fit_transform(x_train), dtype=torch.float32)\n",
        "X_test = torch.tensor(scaler.fit_transform(x_test), dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fnJTOdiEphhm"
      },
      "outputs": [],
      "source": [
        "input_dim = X_train.shape[1]\n",
        "hidden1_dim = 128\n",
        "hidden2_dim = 32\n",
        "output_dim = n_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dXsGpxLhqYoa"
      },
      "outputs": [],
      "source": [
        "w1 = torch.randn(input_dim, hidden1_dim, requires_grad=True)\n",
        "w1.retain_grad()\n",
        "b1 = torch.zeros(hidden1_dim, requires_grad=True)\n",
        "b1.retain_grad()\n",
        "w2 = torch.randn(hidden1_dim, hidden2_dim, requires_grad=True)\n",
        "w2.retain_grad()\n",
        "b2 = torch.zeros(hidden2_dim, requires_grad=True)\n",
        "b2.retain_grad()\n",
        "w3 = torch.randn(hidden2_dim, output_dim, requires_grad=True)\n",
        "w3.retain_grad()\n",
        "b3 = torch.zeros(output_dim, requires_grad=True)\n",
        "b3.retain_grad()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LULXVMs_phhn"
      },
      "outputs": [],
      "source": [
        "def relu(x):\n",
        "  return torch.max(x, torch.zeros_like(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "KuhnYGyaqdJv"
      },
      "outputs": [],
      "source": [
        "def softmax(x):\n",
        "  ex = torch.exp(x - torch.max(x, dim=1, keepdim=True)[0])\n",
        "  return ex / ex.sum(dim=1, keepdim=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mZG6GtDbqfLb"
      },
      "outputs": [],
      "source": [
        "def forward(X):\n",
        "  z1 = torch.matmul(X, w1) + b1\n",
        "  a1 = relu(z1)\n",
        "\n",
        "  z2 = torch.matmul(a1, w2) + b2\n",
        "  a2 = relu(z2)\n",
        "\n",
        "  z3 = torch.matmul(a2, w3) + b3\n",
        "  a3 = softmax(z3)\n",
        "  return a3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "R56dUz2eqgzD"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "err = 1e-10\n",
        "\n",
        "def cross_entropy(pred, truth):\n",
        "  truth_onehot = F.one_hot(truth, num_classes=output_dim).float()\n",
        "  loss = -torch.sum(truth_onehot * torch.log(pred+err), dim=1)\n",
        "  return torch.mean(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "XDKWbOJyphhn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [250/2000], \tLoss: 17.790040969848633\n",
            "Epoch [500/2000], \tLoss: 15.85260009765625\n",
            "Epoch [750/2000], \tLoss: 14.826966285705566\n",
            "Epoch [1000/2000], \tLoss: 14.255081176757812\n",
            "Epoch [1250/2000], \tLoss: 13.806451797485352\n",
            "Epoch [1500/2000], \tLoss: 13.53281307220459\n",
            "Epoch [1750/2000], \tLoss: 13.31104564666748\n",
            "Epoch [2000/2000], \tLoss: 13.1246919631958\n"
          ]
        }
      ],
      "source": [
        "learning_rate = 0.01\n",
        "epochs = 2000\n",
        "\n",
        "for i in range(epochs):\n",
        "  y_pred = forward(X_train)\n",
        "  loss = cross_entropy(y_pred, y_train)\n",
        "  loss.backward()\n",
        "  with torch.no_grad():\n",
        "    w1 -= learning_rate * w1.grad\n",
        "    b1 -= learning_rate * b1.grad\n",
        "    w2 -= learning_rate * w2.grad\n",
        "    b2 -= learning_rate * b2.grad\n",
        "    w3 -= learning_rate * w3.grad\n",
        "    b3 -= learning_rate * b3.grad\n",
        "  w1.grad.zero_()\n",
        "  b1.grad.zero_()\n",
        "  w2.grad.zero_()\n",
        "  b2.grad.zero_()\n",
        "  w3.grad.zero_()\n",
        "  b3.grad.zero_()\n",
        "\n",
        "  if (i + 1) % 250 == 0:\n",
        "    print(f\"Epoch [{i+1}/{epochs}], \\tLoss: {loss.item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "PJHG0bxWphhn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on the test set: 42.17%\n"
          ]
        }
      ],
      "source": [
        "y_pred_test = forward(X_test)\n",
        "_, predicted_labels = torch.max(y_pred_test, 1)\n",
        "\n",
        "correct_predictions = (predicted_labels == y_test).sum().item()\n",
        "accuracy = correct_predictions / len(y_test)\n",
        "print(f\"Accuracy on the test set: {accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yczyk1aJphho"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
