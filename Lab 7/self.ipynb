{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd71e2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Common input parameters\n",
    "batch_size = 5\n",
    "seq_len = 7\n",
    "input_size = 10\n",
    "hidden_size = 20\n",
    "num_layers = 1\n",
    "\n",
    "# Create input tensor\n",
    "x = torch.randn(batch_size, seq_len, input_size)  # For nn.RNN/LSTM/GRU\n",
    "x_cell = torch.randn(seq_len, batch_size, input_size)  # For RNNCell/LSTMCell/GRUCell\n",
    "\n",
    "print(\"\\n========== 1. nn.RNN ==========\")\n",
    "# 1. RNN\n",
    "rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "h0 = torch.randn(num_layers, batch_size, hidden_size)\n",
    "out_rnn, hn_rnn = rnn(x, h0)\n",
    "print(\"RNN Output Shape:\", out_rnn.shape)\n",
    "print(\"RNN Hidden State Shape:\", hn_rnn.shape)\n",
    "\n",
    "print(\"\\n========== 2. nn.LSTM ==========\")\n",
    "# 2. LSTM\n",
    "lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "h0_lstm = torch.randn(num_layers, batch_size, hidden_size)\n",
    "c0_lstm = torch.randn(num_layers, batch_size, hidden_size)\n",
    "out_lstm, (hn_lstm, cn_lstm) = lstm(x, (h0_lstm, c0_lstm))\n",
    "print(\"LSTM Output Shape:\", out_lstm.shape)\n",
    "print(\"LSTM Hidden State Shape:\", hn_lstm.shape)\n",
    "print(\"LSTM Cell State Shape:\", cn_lstm.shape)\n",
    "\n",
    "print(\"\\n========== 3. nn.GRU ==========\")\n",
    "# 3. GRU\n",
    "gru = nn.GRU(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "h0_gru = torch.randn(num_layers, batch_size, hidden_size)\n",
    "out_gru, hn_gru = gru(x, h0_gru)\n",
    "print(\"GRU Output Shape:\", out_gru.shape)\n",
    "print(\"GRU Hidden State Shape:\", hn_gru.shape)\n",
    "\n",
    "print(\"\\n========== 4. nn.RNNCell ==========\")\n",
    "# 4. RNNCell\n",
    "rnn_cell = nn.RNNCell(input_size=input_size, hidden_size=hidden_size)\n",
    "hx_rnn_cell = torch.randn(batch_size, hidden_size)\n",
    "outputs_rnn_cell = []\n",
    "for i in range(seq_len):\n",
    "    hx_rnn_cell = rnn_cell(x_cell[i], hx_rnn_cell)\n",
    "    outputs_rnn_cell.append(hx_rnn_cell)\n",
    "outputs_rnn_cell = torch.stack(outputs_rnn_cell, dim=0)\n",
    "print(\"RNNCell Output Shape:\", outputs_rnn_cell.shape)\n",
    "\n",
    "print(\"\\n========== 5. nn.LSTMCell ==========\")\n",
    "# 5. LSTMCell\n",
    "lstm_cell = nn.LSTMCell(input_size=input_size, hidden_size=hidden_size)\n",
    "hx_lstm_cell = torch.randn(batch_size, hidden_size)  # hidden\n",
    "cx_lstm_cell = torch.randn(batch_size, hidden_size)  # cell\n",
    "outputs_lstm_cell = []\n",
    "for i in range(seq_len):\n",
    "    hx_lstm_cell, cx_lstm_cell = lstm_cell(x_cell[i], (hx_lstm_cell, cx_lstm_cell))\n",
    "    outputs_lstm_cell.append(hx_lstm_cell)\n",
    "outputs_lstm_cell = torch.stack(outputs_lstm_cell, dim=0)\n",
    "print(\"LSTMCell Output Shape:\", outputs_lstm_cell.shape)\n",
    "\n",
    "print(\"\\n========== 6. nn.GRUCell ==========\")\n",
    "# 6. GRUCell\n",
    "gru_cell = nn.GRUCell(input_size=input_size, hidden_size=hidden_size)\n",
    "hx_gru_cell = torch.randn(batch_size, hidden_size)\n",
    "outputs_gru_cell = []\n",
    "for i in range(seq_len):\n",
    "    hx_gru_cell = gru_cell(x_cell[i], hx_gru_cell)\n",
    "    outputs_gru_cell.append(hx_gru_cell)\n",
    "outputs_gru_cell = torch.stack(outputs_gru_cell, dim=0)\n",
    "print(\"GRUCell Output Shape:\", outputs_gru_cell.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4c8355",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self, input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, sequence_length=sequence_length, num_classes=num_classes):\n",
    "        super(SimpleLSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_size * sequence_length, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device=device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device=device)\n",
    "        \n",
    "        out, _ = self.lstm(x,(h0, c0))\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e44baab",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7191d14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleLSTM().to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd24800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class MnistDataset(Dataset):\n",
    "    def __init__(self, datapath):\n",
    "        super(MnistDataset).__init__()\n",
    "        df = pd.read_csv(datapath, dtype=np.float)\n",
    "        \n",
    "        self.x = torch.from_numpy(df.iloc[:, 1:].values)\n",
    "        self.x = self.x.reshape(self.x.size(0), 1, 28, 28).squeeze(1) # GRU and RNN expect N * 28 * 28\n",
    "        self.x = self.x.float()\n",
    "        \n",
    "        self.y = torch.from_numpy(df.iloc[:, 0].values)\n",
    "        self.y = self.y.long()\n",
    "        \n",
    "        self.n_samples = df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69008deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MnistDataset(\"../input/mnist-in-csv/mnist_train.csv\")\n",
    "test_dataset = MnistDataset(\"../input/mnist-in-csv/mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a97af02",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8e43b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_criterion  = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdab98f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_loss = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for data, target in train_dataloader:\n",
    "        data = data.to(device=device)\n",
    "        target = target.to(device=device)\n",
    "        \n",
    "        score = model(data)\n",
    "        loss = loss_criterion(score, target)\n",
    "        current_loss = loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "    print(f\"At epoch: {epoch}, loss: {current_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d176e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(dlr,model):\n",
    "    \n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in dlr:\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "            \n",
    "            score = model(x)\n",
    "            _,predictions = score.max(1)\n",
    "            \n",
    "            total_correct += (y==predictions).sum()\n",
    "            total_samples += predictions.size(0)\n",
    "            \n",
    "    model.train()\n",
    "    print(f\"total samples: {total_samples} total_correct: {total_correct} accuracy : {float(total_correct/total_samples)* 100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b95604",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
